{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b909e49-7406-4e1b-b87e-8f7852b549db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T02:14:52.151835Z",
     "start_time": "2024-03-26T02:14:51.065430Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\Grid\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import transformers\n",
    "import torch\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import higher\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef63d6c-62fc-4a39-a124-b0f236297534",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T02:14:53.197113Z",
     "start_time": "2024-03-26T02:14:53.185114Z"
    }
   },
   "outputs": [],
   "source": [
    "## Credits\n",
    "## This cell includes code from StylePTB (https://github.com/lvyiwei1/StylePTB/tree/master) by Yiwei Lyu et al., \n",
    "## available under the Creative Commons Attribution 4.0 International License ([CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)).\n",
    "\n",
    "def lowering(pairs):\n",
    "    for pair in pairs:\n",
    "        for i in range(0, 2):\n",
    "            pair[i] = pair[i].lower()\n",
    "\n",
    "def numpreprocess(pairs):\n",
    "    for pair in pairs:\n",
    "        for i in range(0, 2):\n",
    "            rep = []\n",
    "            for word in pair[i].split(' '):\n",
    "                if len(word) > 0 and word[0] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']:\n",
    "                    rep.append(\"NUM\")\n",
    "                else:\n",
    "                    rep.append(word)\n",
    "            pair[i] = ' '.join(rep)\n",
    "\n",
    "def padinput(inputlist, totalpad=80):\n",
    "    pads = [0] * (totalpad - len(inputlist))\n",
    "    input = inputlist + pads\n",
    "    mask = [1] * len(inputlist) + pads\n",
    "    return input, mask\n",
    "\n",
    "# create label for training\n",
    "def labels(inlen, outputlist, totalpad=80):\n",
    "    pads1 = [-100] * inlen\n",
    "    pads2 = [-100] * (totalpad - inlen - len(outputlist))\n",
    "    # print(outputlist)\n",
    "    return pads1 + outputlist + pads2\n",
    "\n",
    "def batchvalid(src, trg, batchsize):\n",
    "    validloss = 0.0\n",
    "    for i in range(0, len(src) // batchsize):\n",
    "        asrc = []\n",
    "        atrg = []\n",
    "        for pair in src[i * batchsize:(i + 1) * batchsize]:\n",
    "            asrc.append(pair)\n",
    "        for pair in trg[i * batchsize:(i + 1) * batchsize]:\n",
    "            atrg.append(pair)\n",
    "        validloss += valid(asrc, atrg)\n",
    "    return validloss / (len(src) // batchsize)\n",
    "\n",
    "def valid(src, trg):\n",
    "    padin = [padinput(l) for l in src]\n",
    "    padedin = torch.LongTensor([padin[i][0] for i in range(0, len(trg))]).to(device)\n",
    "    masks = torch.LongTensor([padin[i][1] for i in range(0, len(trg))]).to(device)\n",
    "    label = torch.LongTensor([labels(len(src[i]), trg[i]) for i in range(0, len(trg))]).to(device)\n",
    "    with torch.no_grad():\n",
    "        ret = gpt_model.forward(padedin, attention_mask=masks, labels=label)\n",
    "        loss = ret[0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3caf2c59-257f-45ef-ba64-bca2d8318060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T02:14:53.766296Z",
     "start_time": "2024-03-26T02:14:53.751233Z"
    }
   },
   "outputs": [],
   "source": [
    "class MAML_GPT():\n",
    "    def __init__(self, gpt_model, tasks, device, gpt_tokenizer=None, inner_lr=2e-4, meta_lr=2e-5, K=10, \n",
    "                 multi_batch_iter=1, inner_steps=1, early_stop=50, model_save_name=\"maml_gpt\"):\n",
    "        self.tasks = tasks\n",
    "        self.model = gpt_model\n",
    "        self.gpt_tokenizer = gpt_tokenizer\n",
    "        #self.criterion = nn.MSELoss()\n",
    "        self.meta_optimiser = optim.Adam(self.model.parameters(), meta_lr)\n",
    "        self.inner_lr = inner_lr\n",
    "        self.meta_lr = meta_lr\n",
    "        self.K = K\n",
    "        self.inner_steps = inner_steps\n",
    "        self.plot_every = 1\n",
    "        self.print_every = 1\n",
    "        self.meta_losses = []\n",
    "        self.early_stop = early_stop\n",
    "        self.meta_batch_size = len(tasks)\n",
    "        self.model_save_name = model_save_name\n",
    "        self.multi_batch_iter = multi_batch_iter\n",
    "        self.device = device\n",
    "        \n",
    "    def inner_loop(self, task):\n",
    "        self.inner_loop_counter += 1\n",
    "        \n",
    "        start_inner_time = time.time()  # 开始计时\n",
    "        if torch.cuda.is_available():\n",
    "            start_inner_mem = torch.cuda.memory_allocated()  # 获取开始时的显存使用情况\n",
    "        print(f\"Start inner loop {self.inner_loop_counter}.\")\n",
    "        print(f\"Current memory used: {(start_inner_mem) / (1024 ** 2)} MB.\")\n",
    "\n",
    "        with higher.innerloop_ctx(self.model, self.inner_opt, copy_initial_weights=False) as (fmodel, diffopt):\n",
    "        \n",
    "            copy_time = time.time()\n",
    "            if torch.cuda.is_available():\n",
    "                copy_mem = torch.cuda.memory_allocated()  # 获取显存使用情况\n",
    "            print(f\"Copy model.\")    \n",
    "            print(f\"Time taken: {copy_time - start_inner_time} seconds; Memory used: {(copy_mem - start_inner_mem) / (1024 ** 2)} MB.\")\n",
    "        \n",
    "            random_selected_samples = random.sample(task, 2*self.K)\n",
    "            inner_train_samples = random_selected_samples[:self.K]\n",
    "            inner_test_samples = random_selected_samples[self.K:]\n",
    "            padedin, masks, labels = self.samples_to_padedin_masks_labels(inner_train_samples)\n",
    "            for step in range(self.inner_steps):\n",
    "                pred = fmodel(padedin, attention_mask=masks, labels=labels)\n",
    "                loss_inner_step = pred[0]\n",
    "                diffopt.step(loss_inner_step)\n",
    "                del pred\n",
    "\n",
    "            end_inner_train_time = time.time()\n",
    "            if torch.cuda.is_available():\n",
    "                end_inner_train_mem = torch.cuda.memory_allocated()  # 获取显存使用情况\n",
    "            print(f\"Finish training copied model.\")    \n",
    "            print(f\"Time taken: {end_inner_train_time - copy_time} seconds; Memory used: {(end_inner_train_mem - copy_mem) / (1024 ** 2)} MB.\")\n",
    "        \n",
    "            padedin, masks, labels = self.samples_to_padedin_masks_labels(inner_test_samples)\n",
    "            pred = fmodel(padedin, attention_mask=masks, labels=labels)\n",
    "            loss = pred[0]\n",
    "            loss.backward()\n",
    "            loss_item = loss.detach().item()\n",
    "\n",
    "            end_inner_test_time = time.time()\n",
    "            if torch.cuda.is_available():\n",
    "                end_inner_test_mem = torch.cuda.memory_allocated()  # 获取显存使用情况\n",
    "            print(f\"Finish testing copied model.\")    \n",
    "            print(f\"Time taken: {end_inner_test_time - end_inner_train_time} seconds; Memory used: {(end_inner_test_mem - end_inner_train_mem) / (1024 ** 2)} MB.\")\n",
    "\n",
    "            del pred\n",
    "            del fmodel\n",
    "            del diffopt\n",
    "            \n",
    "            \n",
    "            end_inner_del_time = time.time()\n",
    "            if torch.cuda.is_available():\n",
    "                end_inner_del_mem = torch.cuda.memory_allocated()  # 获取显存使用情况\n",
    "            print(f\"Release Memory.\")    \n",
    "            print(f\"Time taken: {end_inner_del_time - end_inner_test_time} seconds; Memory used: {(end_inner_del_mem - end_inner_test_mem) / (1024 ** 2)} MB.\")\n",
    "\n",
    "            return loss_item\n",
    "    \n",
    "    def main_loop(self, num_iterations):\n",
    "        min_loss = 999\n",
    "        early_stop_count = 0\n",
    "        print_loss = 0\n",
    "        for iteration in range(1, num_iterations + 1):\n",
    "            self.main_loop_counter = iteration\n",
    "\n",
    "            start_main_time = time.time()  # 开始计时\n",
    "            if torch.cuda.is_available():\n",
    "                start_main_mem = torch.cuda.memory_allocated()  # 获取开始时的显存使用情况\n",
    "            print()\n",
    "            print(f\"Start main loop epoch {iteration}.\")\n",
    "            print(f\"Current memory used: {(start_main_mem) / (1024 ** 2)} MB.\")\n",
    "\n",
    "            self.meta_optimiser.zero_grad()\n",
    "            self.inner_opt = torch.optim.SGD(self.model.parameters(), lr=self.inner_lr)\n",
    "            meta_loss = 0\n",
    "            self.inner_loop_counter = 0\n",
    "            for _ in range(self.multi_batch_iter):\n",
    "                for task in self.tasks:\n",
    "                    meta_loss += self.inner_loop(task)\n",
    "            if meta_loss < min_loss:\n",
    "                min_loss = meta_loss\n",
    "                early_stop_count = 0\n",
    "                print(f\"New lowest loss ({meta_loss / (self.meta_batch_size * self.multi_batch_iter)}) found!\")\n",
    "                torch.save(self.model, f\".\\\\MAML_GPT_models\\\\{self.model_save_name}_epoch{iteration}.pt\")\n",
    "            else:\n",
    "                early_stop_count += 1\n",
    "                if early_stop_count > self.early_stop:\n",
    "                    print(f\"Early stop at epoch {iteration} because no lower loss is found in {self.early_stop} epochs\")\n",
    "                    return\n",
    "\n",
    "            finish_all_inner_time = time.time()\n",
    "            if torch.cuda.is_available():\n",
    "                finish_all_inner_mem = torch.cuda.memory_allocated()  # 获取显存使用情况\n",
    "            print(f\"Finish all inner loops in this epoch.\")    \n",
    "            print(f\"Time taken: {finish_all_inner_time - start_main_time} seconds; Memory used: {(finish_all_inner_mem - start_main_mem) / (1024 ** 2)} MB.\")\n",
    "            \n",
    "            #self.meta_optimiser.zero_grad()\n",
    "            #meta_loss.backward()\n",
    "            self.meta_optimiser.step()\n",
    "\n",
    "            finish_meta_update_time = time.time()\n",
    "            if torch.cuda.is_available():\n",
    "                finish_meta_update_mem = torch.cuda.memory_allocated()  # 获取显存使用情况\n",
    "            print(f\"Finish meta update in this epoch.\")    \n",
    "            print(f\"Time taken: {finish_meta_update_time - finish_all_inner_time} seconds; Memory used: {(finish_meta_update_mem - finish_all_inner_mem) / (1024 ** 2)} MB.\")\n",
    "            \n",
    "            print_loss += meta_loss / (self.meta_batch_size * self.multi_batch_iter)\n",
    "            if iteration % self.print_every == 0:\n",
    "                print(f\"Epoch {iteration}/{num_iterations}. loss: {print_loss / self.print_every}\")\n",
    "                print_loss = 0\n",
    "            if iteration % self.plot_every == 0:\n",
    "                self.meta_losses.append(meta_loss / (self.meta_batch_size * self.multi_batch_iter))\n",
    "\n",
    "    def start_train(self, epochs=10000):\n",
    "        self.epochs = epochs\n",
    "        self.main_loop(self.epochs)\n",
    "\n",
    "    def samples_to_padedin_masks_labels(self, samples):\n",
    "        src = []\n",
    "        trg = []\n",
    "        for sample in samples:\n",
    "            src.append(sample[0])\n",
    "            trg.append(sample[1])\n",
    "        padin = [self.padinput(l) for l in src]\n",
    "        padedin = torch.LongTensor([padin[i][0] for i in range(0, len(trg))]).to(self.device)\n",
    "        masks = torch.LongTensor([padin[i][1] for i in range(0, len(trg))]).to(self.device)\n",
    "        labels = torch.LongTensor([self.create_labels(len(src[i]), trg[i]) for i in range(0, len(trg))]).to(self.device)\n",
    "        return padedin, masks, labels\n",
    "\n",
    "    def create_labels(self, inlen, outputlist, totalpad=80):\n",
    "        pads1 = [-100] * inlen\n",
    "        pads2 = [-100] * (totalpad - inlen - len(outputlist))\n",
    "        return pads1 + outputlist + pads2\n",
    "    \n",
    "    def padinput(self, inputlist, totalpad=80):\n",
    "        pads = [0] * (totalpad - len(inputlist))\n",
    "        input = inputlist + pads\n",
    "        mask = [1] * len(inputlist) + pads\n",
    "        return input, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e9f4364-1c2c-44cf-9515-10c5a39252f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T02:14:57.207614Z",
     "start_time": "2024-03-26T02:14:53.939349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "# Pre-process the data\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"Device: {device}\")\n",
    "gpt_tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt_model = transformers.GPT2LMHeadModel.from_pretrained('gpt2').to(device)\n",
    "meta_train_task_name_list = [\"ARR\", \"TFU\", \"ATP\", \"PPR\", \"TPA\"]\n",
    "meta_test_task_name_list = [\"PTA\", \"SBR\", \"TPR\"]\n",
    "\n",
    "train_task_pair_list = [] # Nested list with pairs from different tasks\n",
    "for meta_train_task_name in meta_train_task_name_list:\n",
    "    f = open(f'.\\\\Data\\\\Meta_training\\\\{meta_train_task_name}\\\\train.tsv', 'r')\n",
    "    ff = csv.reader(f, delimiter='\\t')\n",
    "    pairs = []\n",
    "    for row in ff:\n",
    "        pairs.append(row)\n",
    "    lowering(pairs)\n",
    "    numpreprocess(pairs)\n",
    "    pairsEncode = []\n",
    "    for i in pairs:\n",
    "        pairsEncode.append((gpt_tokenizer.encode(i[0] + \" <|endoftext|>\"), gpt_tokenizer.encode(i[1] + \" <|endoftext|>\")))\n",
    "    train_task_pair_list.append(pairsEncode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d6ae7e-b65e-4ba6-b546-4447a3bdac2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T02:14:57.238728Z",
     "start_time": "2024-03-26T02:14:57.220617Z"
    }
   },
   "outputs": [],
   "source": [
    "maml_gpt = MAML_GPT(gpt_model=gpt_model, tasks=train_task_pair_list, device = device, gpt_tokenizer=gpt_tokenizer, \n",
    "                    multi_batch_iter=1, early_stop=50, model_save_name=\"maml_gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d543cd5-c31d-4dd3-a94b-863ba853e8f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T02:30:28.857492Z",
     "start_time": "2024-03-26T02:30:01.736221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start main loop epoch 1.\n",
      "Current memory used: 487.46875 MB.\n",
      "Start inner loop 1.\n",
      "Current memory used: 487.46875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.030536890029907227 seconds; Memory used: 487.46875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 2.1391077041625977 seconds; Memory used: 2649.1904296875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4252641201019287 seconds; Memory used: -1287.10693359375 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.71875 MB.\n",
      "Start inner loop 2.\n",
      "Current memory used: 981.4970703125 MB.\n",
      "Copy model.\n",
      "Time taken: 0.015641450881958008 seconds; Memory used: 492.2314453125 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04686546325683594 seconds; Memory used: 2635.9482421875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4159228801727295 seconds; Memory used: -1768.85693359375 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 3.\n",
      "Current memory used: 981.4970703125 MB.\n",
      "Copy model.\n",
      "Time taken: 0.016017913818359375 seconds; Memory used: 492.2314453125 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04688739776611328 seconds; Memory used: 2635.9482421875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4253406524658203 seconds; Memory used: -1768.85693359375 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0010006427764892578 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 4.\n",
      "Current memory used: 981.4970703125 MB.\n",
      "Copy model.\n",
      "Time taken: 0.006036281585693359 seconds; Memory used: 492.2314453125 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04729008674621582 seconds; Memory used: 2635.9482421875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.41768741607666016 seconds; Memory used: -1768.85693359375 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 5.\n",
      "Current memory used: 981.4970703125 MB.\n",
      "Copy model.\n",
      "Time taken: 0.015625 seconds; Memory used: 492.2314453125 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04725289344787598 seconds; Memory used: 2635.9482421875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.405550479888916 seconds; Memory used: -1768.85693359375 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "New lowest loss (9.718565368652344) found!\n",
      "Finish all inner loops in this epoch.\n",
      "Time taken: 5.132518529891968 seconds; Memory used: 494.0283203125 MB.\n",
      "Finish meta update in this epoch.\n",
      "Time taken: 0.021006345748901367 seconds; Memory used: 957.4072265625 MB.\n",
      "Epoch 1/50. loss: 9.718565368652344\n",
      "\n",
      "Start main loop epoch 2.\n",
      "Current memory used: 1938.904296875 MB.\n",
      "Start inner loop 1.\n",
      "Current memory used: 1461.1259765625 MB.\n",
      "Copy model.\n",
      "Time taken: 0.021886825561523438 seconds; Memory used: 488.2998046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04676365852355957 seconds; Memory used: 2634.5966796875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4121589660644531 seconds; Memory used: -1289.31591796875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0010004043579101562 seconds; Memory used: -238.546875 MB.\n",
      "Start inner loop 2.\n",
      "Current memory used: 1940.6826171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.007928848266601562 seconds; Memory used: 490.7734375 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04676675796508789 seconds; Memory used: 2634.013671875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.6495521068572998 seconds; Memory used: -1768.72412109375 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0007803440093994141 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 3.\n",
      "Current memory used: 1940.6826171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.018314838409423828 seconds; Memory used: 490.7734375 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04196882247924805 seconds; Memory used: 2634.013671875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4141066074371338 seconds; Memory used: -1768.72412109375 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0009999275207519531 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 4.\n",
      "Current memory used: 1940.6826171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.01563739776611328 seconds; Memory used: 490.7734375 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.031255483627319336 seconds; Memory used: 2634.013671875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.43276309967041016 seconds; Memory used: -1768.72412109375 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 5.\n",
      "Current memory used: 1940.6826171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.018883705139160156 seconds; Memory used: 490.7734375 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.0424191951751709 seconds; Memory used: 2634.013671875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4116499423980713 seconds; Memory used: -1768.72412109375 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "New lowest loss (8.960723114013671) found!\n",
      "Finish all inner loops in this epoch.\n",
      "Time taken: 3.149897575378418 seconds; Memory used: 1.7783203125 MB.\n",
      "Finish meta update in this epoch.\n",
      "Time taken: 0.010009288787841797 seconds; Memory used: 0.0 MB.\n",
      "Epoch 2/50. loss: 8.960723114013671\n",
      "\n",
      "Start main loop epoch 3.\n",
      "Current memory used: 1940.6826171875 MB.\n",
      "Start inner loop 1.\n",
      "Current memory used: 1461.1259765625 MB.\n",
      "Copy model.\n",
      "Time taken: 0.019998788833618164 seconds; Memory used: 488.2998046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.03999948501586914 seconds; Memory used: 2634.5966796875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.41976165771484375 seconds; Memory used: -1290.29736328125 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0009219646453857422 seconds; Memory used: -238.546875 MB.\n",
      "Start inner loop 2.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.014781713485717773 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04607820510864258 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.41502809524536133 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0009989738464355469 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 3.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.017972230911254883 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.03917098045349121 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.41230320930480957 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 4.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.02430558204650879 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.036354780197143555 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.41896915435791016 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0009984970092773438 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 5.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.019719362258911133 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.03624081611633301 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4238431453704834 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0010318756103515625 seconds; Memory used: -238.375 MB.\n",
      "New lowest loss (8.530678367614746) found!\n",
      "Finish all inner loops in this epoch.\n",
      "Time taken: 2.9467809200286865 seconds; Memory used: -0.9814453125 MB.\n",
      "Finish meta update in this epoch.\n",
      "Time taken: 0.0019617080688476562 seconds; Memory used: 0.0 MB.\n",
      "Epoch 3/50. loss: 8.530678367614746\n",
      "\n",
      "Start main loop epoch 4.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Start inner loop 1.\n",
      "Current memory used: 1461.1259765625 MB.\n",
      "Copy model.\n",
      "Time taken: 0.01790022850036621 seconds; Memory used: 488.2998046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04786229133605957 seconds; Memory used: 2634.5966796875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4093513488769531 seconds; Memory used: -1290.29736328125 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.005071878433227539 seconds; Memory used: -238.546875 MB.\n",
      "Start inner loop 2.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.018147945404052734 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.042478322982788086 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4121124744415283 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.010019540786743164 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 3.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.02053546905517578 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.03889203071594238 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.41539764404296875 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 4.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.019220352172851562 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04148292541503906 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4126443862915039 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 5.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.018217086791992188 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04483199119567871 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.40486907958984375 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "New lowest loss (8.09089527130127) found!\n",
      "Finish all inner loops in this epoch.\n",
      "Time taken: 3.0342750549316406 seconds; Memory used: 0.0 MB.\n",
      "Finish meta update in this epoch.\n",
      "Time taken: 0.002779245376586914 seconds; Memory used: 0.0 MB.\n",
      "Epoch 4/50. loss: 8.09089527130127\n",
      "\n",
      "Start main loop epoch 5.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Start inner loop 1.\n",
      "Current memory used: 1461.1259765625 MB.\n",
      "Copy model.\n",
      "Time taken: 0.018894672393798828 seconds; Memory used: 488.2998046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04983067512512207 seconds; Memory used: 2634.5966796875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4005894660949707 seconds; Memory used: -1290.29736328125 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.005106687545776367 seconds; Memory used: -238.546875 MB.\n",
      "Start inner loop 2.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.018418550491333008 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.042405128479003906 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.41478466987609863 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 3.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.02000117301940918 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04001259803771973 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4217989444732666 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 4.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.024370193481445312 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.03705239295959473 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4176356792449951 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 5.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.019087791442871094 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.041548728942871094 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4169766902923584 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0005409717559814453 seconds; Memory used: -238.375 MB.\n",
      "New lowest loss (7.881347274780273) found!\n",
      "Finish all inner loops in this epoch.\n",
      "Time taken: 2.923952102661133 seconds; Memory used: 0.0 MB.\n",
      "Finish meta update in this epoch.\n",
      "Time taken: 0.0 seconds; Memory used: 0.0 MB.\n",
      "Epoch 5/50. loss: 7.881347274780273\n",
      "\n",
      "Start main loop epoch 6.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Start inner loop 1.\n",
      "Current memory used: 1461.1259765625 MB.\n",
      "Copy model.\n",
      "Time taken: 0.1415095329284668 seconds; Memory used: 488.2998046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.0372769832611084 seconds; Memory used: 2634.5966796875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.41724562644958496 seconds; Memory used: -1290.29736328125 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.001050710678100586 seconds; Memory used: -238.546875 MB.\n",
      "Start inner loop 2.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.01821422576904297 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.039994239807128906 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.41365671157836914 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 3.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.01933002471923828 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.0435333251953125 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.41497349739074707 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.00012564659118652344 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 4.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.019100427627563477 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.040363311767578125 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4131808280944824 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 5.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.018849849700927734 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.039888620376586914 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.42218518257141113 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0009999275207519531 seconds; Memory used: -238.375 MB.\n",
      "New lowest loss (7.38353910446167) found!\n",
      "Finish all inner loops in this epoch.\n",
      "Time taken: 3.0657875537872314 seconds; Memory used: 0.0 MB.\n",
      "Finish meta update in this epoch.\n",
      "Time taken: 0.002109527587890625 seconds; Memory used: 0.0 MB.\n",
      "Epoch 6/50. loss: 7.38353910446167\n",
      "\n",
      "Start main loop epoch 7.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Start inner loop 1.\n",
      "Current memory used: 1461.1259765625 MB.\n",
      "Copy model.\n",
      "Time taken: 0.0180361270904541 seconds; Memory used: 488.2998046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.049475669860839844 seconds; Memory used: 2634.5966796875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4146416187286377 seconds; Memory used: -1290.29736328125 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.546875 MB.\n",
      "Start inner loop 2.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.017964601516723633 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04082942008972168 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4122745990753174 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 3.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.01856064796447754 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.036305904388427734 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.42313289642333984 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 4.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.014925003051757812 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.044377803802490234 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.41803431510925293 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 5.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.018341064453125 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.03553342819213867 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.41991281509399414 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "New lowest loss (6.790062522888183) found!\n",
      "Finish all inner loops in this epoch.\n",
      "Time taken: 10.2909574508667 seconds; Memory used: 0.0 MB.\n",
      "Finish meta update in this epoch.\n",
      "Time taken: 0.0030145645141601562 seconds; Memory used: 0.0 MB.\n",
      "Epoch 7/50. loss: 6.790062522888183\n",
      "\n",
      "Start main loop epoch 8.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Start inner loop 1.\n",
      "Current memory used: 1461.1259765625 MB.\n",
      "Copy model.\n",
      "Time taken: 0.005982637405395508 seconds; Memory used: 488.2998046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.3072686195373535 seconds; Memory used: 2634.5966796875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4133009910583496 seconds; Memory used: -1290.29736328125 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0007567405700683594 seconds; Memory used: -238.546875 MB.\n",
      "Start inner loop 2.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.01826643943786621 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04117918014526367 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4042630195617676 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.00099945068359375 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 3.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.01745891571044922 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.03945136070251465 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.40692138671875 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 4.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.018927335739135742 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.03899550437927246 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.4125661849975586 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0011241436004638672 seconds; Memory used: -238.375 MB.\n",
      "Start inner loop 5.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.0181121826171875 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.039960622787475586 seconds; Memory used: 2632.7939453125 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.3998703956604004 seconds; Memory used: -1767.42919921875 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.015625 seconds; Memory used: -238.375 MB.\n",
      "Finish all inner loops in this epoch.\n",
      "Time taken: 2.6099705696105957 seconds; Memory used: 0.0 MB.\n",
      "Finish meta update in this epoch.\n",
      "Time taken: 0.0 seconds; Memory used: 0.0 MB.\n",
      "Epoch 8/50. loss: 6.807553768157959\n",
      "\n",
      "Start main loop epoch 9.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Start inner loop 1.\n",
      "Current memory used: 1461.1259765625 MB.\n",
      "Copy model.\n",
      "Time taken: 0.016020774841308594 seconds; Memory used: 488.2998046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.04850935935974121 seconds; Memory used: 2634.5966796875 MB.\n",
      "Finish testing copied model.\n",
      "Time taken: 0.40608835220336914 seconds; Memory used: -1290.29736328125 MB.\n",
      "Release Memory.\n",
      "Time taken: 0.0 seconds; Memory used: -238.546875 MB.\n",
      "Start inner loop 2.\n",
      "Current memory used: 1939.701171875 MB.\n",
      "Copy model.\n",
      "Time taken: 0.022401094436645508 seconds; Memory used: 490.5498046875 MB.\n",
      "Finish training copied model.\n",
      "Time taken: 0.03817582130432129 seconds; Memory used: 2632.7939453125 MB.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmaml_gpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_train\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 137\u001b[0m, in \u001b[0;36mMAML_GPT.start_train\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m):\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m=\u001b[39m epochs\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 100\u001b[0m, in \u001b[0;36mMAML_GPT.main_loop\u001b[1;34m(self, num_iterations)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_batch_iter):\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks:\n\u001b[1;32m--> 100\u001b[0m         meta_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meta_loss \u001b[38;5;241m<\u001b[39m min_loss:\n\u001b[0;32m    102\u001b[0m     min_loss \u001b[38;5;241m=\u001b[39m meta_loss\n",
      "Cell \u001b[1;32mIn[3], line 58\u001b[0m, in \u001b[0;36mMAML_GPT.inner_loop\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m     56\u001b[0m pred \u001b[38;5;241m=\u001b[39m fmodel(padedin, attention_mask\u001b[38;5;241m=\u001b[39mmasks, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[0;32m     57\u001b[0m loss \u001b[38;5;241m=\u001b[39m pred[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 58\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m loss_item \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     61\u001b[0m end_inner_test_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\Grid\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\Grid\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "maml_gpt.start_train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431024c-804e-4902-83dd-079967e05375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
